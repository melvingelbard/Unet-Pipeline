{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os, sys\n",
    "import torch.optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from dataloader import *\n",
    "from models import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = '/home/pete/melvin/nuclei_segmentation/data/images'\n",
    "train_target_path = '/home/pete/melvin/nuclei_segmentation/data/labels_3_classes'\n",
    "\n",
    "eval_input_path = '/home/pete/melvin/nuclei_segmentation/data/eval/images'\n",
    "eval_target_path = '/home/pete/melvin/nuclei_segmentation/data/eval/labels_3_classes'\n",
    "\n",
    "stats_path = \"/home/pete/melvin/nuclei_segmentation/stats.txt\"\n",
    "\n",
    "transform_params = {\"cropping_width\":448, \"cropping_height\":448, \"h_flip\":0.5, \"v_flip\":0.5, \"normalise\":False}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 8\n",
    "n_class = 3\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the path to cross validation images and annotations.\n",
    "# CV_image_paths='.\\Red_vs_Yellow_Results\\ANN_L1_ModRes\\CV\\Original_Images'\n",
    "# CV_target_paths='.\\Red_vs_Yellow_Results\\ANN_L1_ModRes\\CV\\Annotated_Images'\n",
    "\n",
    "# Create a dataset for training.\n",
    "train_dataset = Nuclei_Dataset(train_input_path, train_target_path, transform_params)\n",
    "\n",
    "\n",
    "# Create a dataset for evaluation.\n",
    "eval_dataset = Nuclei_Dataset(eval_input_path, eval_target_path, transform_params, train=False)\n",
    "\n",
    "# Create a dataset from the CV images and annotations.\n",
    "# CV_dataset=MyDataset(CV_image_paths, CV_target_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "        eval_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dict for parameters to pass to train function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"stats_path\": stats_path,\n",
    "              \"device\": device, \n",
    "              \"batch_size\": 4, \n",
    "              \"n_class\": n_class, \n",
    "              \"datasets\": [train_dataset, eval_dataset],\n",
    "              \"loaders\": [train_loader, eval_loader]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See what a batch looks like ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Examine a single batch from the dataset.\n",
    "batch = next(iter(train_loader))\n",
    "inputs, targets = batch\n",
    "\n",
    "\n",
    "# Plot a batch of images.\n",
    "fig, ax = plt.subplots(inputs.shape[0],2,figsize=(25, 25))\n",
    "for i in range(inputs.shape[0]):\n",
    "    ax[i, 0].imshow(inputs[i].permute(1,2,0))\n",
    "    ax[i, 1].imshow(targets[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise the model and train it ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "## Will try weight 0 --> 50\n",
    "for weight_factor in range(3, 4):\n",
    "    model = ResNetUNet(n_class)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # freeze backbone layers\n",
    "    # Comment out to finetune further\n",
    "    for l in model.base_layers:\n",
    "        for param in l.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    ## Create Adam optimiser\n",
    "    optimizer_ft = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    ## Create scheduler for learning rate decay\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=0.1)\n",
    "\n",
    "    weight_cpu = np.array([0.85, 1,  0.85])\n",
    "    weights = torch.from_numpy(np.array([1, weight_factor/2, 1])).cuda().float()\n",
    "    model = train_model(model, parameters, optimizer_ft, exp_lr_scheduler, weights=weights, progress_bars=False, perclass_stat=True, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_of_batches_to_check = 5\n",
    "\n",
    "for batch in range(num_of_batches_to_check):\n",
    "    inputs, labels = next(iter(eval_loader))\n",
    "    inputs = inputs.cuda()\n",
    "    out = model(inputs)\n",
    "    _, prediction = torch.max(out, 1)\n",
    "\n",
    "\n",
    "    num_predictions = prediction.shape[0]\n",
    "    fig, ax = plt.subplots(num_predictions, 3, figsize=(25, 25))\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    for i in range(num_predictions):\n",
    "        ax[i%num_predictions, 0].imshow(inputs[i, :, :, :].transpose(0, 1).transpose(1, 2).cpu().numpy())\n",
    "        ax[i%num_predictions, 1].imshow(labels[i])\n",
    "        ax[i%num_predictions, 2].imshow(prediction[i].cpu().numpy())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
